train_loader = DataLoader(train_dataset, 128, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, 256, shuffle=False, num_workers=0)
test_loader = DataLoader(test_dataset, 256, shuffle=False, num_workers=0)

epochs = 20
train_loader = DataLoader(train_dataset, 32, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, 128, shuffle=False, num_workers=0)
test_loader = DataLoader(test_dataset, 128, shuffle=False, num_workers=0)

epochs = 30
model = SubFormer(
    hidden_channels=64,
    out_channels=ds.num_tasks,
    num_mp_layers=3,
    num_enc_layers=5,
    mp_dropout=0.05,
    mp_dropout_edge=0,
    enc_dropout=0.5,
    local_mp='gine',
    learn_gating=True,
    activation='relu',
    back_activation='leaky_relu',
    enc_activation='relu',
    aggregation='mean',
    pe_fea=True,
    pe_dim=10,
    n_head=8,
    padding_length=260,
    d_model=128,
    dim_feedforward=256,
    readout_channels=128,
    concat_pe=True,
    use_deg=True,
    use_lpe=False,
    use_spa=True,
).to(device)
print(model)
model.reset_parameters()
optimizer = Adam(model.parameters(), lr=0.0001,amsgrad=True)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,
                              patience=3, min_lr=0.00001)

SubFormer(
  (local_mp): LocalMP(
    (atom_encoder): AtomEncoder(
      (embeddings): ModuleList(
        (0-8): 9 x Embedding(100, 64)
      )
    )
    (clique_encoder): Embedding(4, 64)
    (activation): ReLU()
    (back_activation): LeakyReLU(negative_slope=0.01)
    (bond_encoders): ModuleList(
      (0-2): 3 x BondEncoder(
        (embeddings): ModuleList(
          (0-2): 3 x Embedding(6, 64)
        )
      )
    )
    (graph_convs): ModuleList(
      (0-2): 3 x GINEConv(nn=Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=64, bias=True)
      ))
    )
    (graph_norms): ModuleList(
      (0-2): 3 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (sub_norms): ModuleList(
      (0-2): 3 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (atom2clique_lins): ModuleList(
      (0-2): 3 x Linear(in_features=64, out_features=64, bias=True)
    )
    (clique2atom_lins): ModuleList(
      (0-2): 3 x Linear(in_features=64, out_features=64, bias=True)
    )
    (clique): Linear(in_features=64, out_features=64, bias=True)
    (pe_lin): Linear(in_features=10, out_features=64, bias=True)
    (cat_lin): Linear(in_features=128, out_features=64, bias=True)
  )
  (pe): PositionalEncoding(
    (activation): ReLU()
    (deg_emb): Embedding(50, 64)
    (deg_lin): Linear(in_features=64, out_features=64, bias=True)
    (deg_merge): Linear(in_features=64, out_features=64, bias=True)
    (spa_lin): Linear(in_features=10, out_features=64, bias=True)
  )
  (encoder): Encoder(
    (activation): ReLU()
    (encoder_layer): TransformerEncoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
      (linear1): Linear(in_features=128, out_features=256, bias=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (linear2): Linear(in_features=256, out_features=128, bias=True)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.5, inplace=False)
      (dropout2): Dropout(p=0.5, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-4): 5 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=256, bias=True)
          (dropout): Dropout(p=0.5, inplace=False)
          (linear2): Linear(in_features=256, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.5, inplace=False)
          (dropout2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (readout): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=1, bias=True)
    )
  )
)

Epoch: 001, Loss: 0.1592, Train: 0.7313, Val: 0.7816, Test: 0.7421
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:54<00:00, 19.02it/s]
Epoch: 002, Loss: 0.1350, Train: 0.7614, Val: 0.7867, Test: 0.7353
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:49<00:00, 20.92it/s]
Epoch: 003, Loss: 0.1293, Train: 0.7865, Val: 0.7426, Test: 0.7353
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:50<00:00, 20.24it/s]
Epoch: 004, Loss: 0.1256, Train: 0.7877, Val: 0.7339, Test: 0.7353
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:50<00:00, 20.24it/s]
Epoch: 005, Loss: 0.1222, Train: 0.7994, Val: 0.7743, Test: 0.7353
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:50<00:00, 20.34it/s]
Epoch: 006, Loss: 0.1203, Train: 0.8025, Val: 0.7904, Test: 0.7600
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:53<00:00, 19.06it/s]
Epoch: 007, Loss: 0.1184, Train: 0.8094, Val: 0.7975, Test: 0.7619
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:54<00:00, 18.73it/s]
Epoch: 008, Loss: 0.1159, Train: 0.8106, Val: 0.7396, Test: 0.7619
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:55<00:00, 18.59it/s]
Epoch: 009, Loss: 0.1117, Train: 0.8217, Val: 0.7802, Test: 0.7619
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:53<00:00, 19.39it/s]
Epoch: 010, Loss: 0.1097, Train: 0.8224, Val: 0.7963, Test: 0.7619
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.82it/s]
Epoch: 011, Loss: 0.1094, Train: 0.8271, Val: 0.8032, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.52it/s]
Epoch: 012, Loss: 0.1088, Train: 0.8282, Val: 0.7738, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:46<00:00, 22.34it/s]
Epoch: 013, Loss: 0.1057, Train: 0.8323, Val: 0.7985, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.50it/s]
Epoch: 014, Loss: 0.1044, Train: 0.8353, Val: 0.7684, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:46<00:00, 22.24it/s]
Epoch: 015, Loss: 0.1046, Train: 0.8329, Val: 0.7798, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:46<00:00, 22.27it/s]
Epoch: 016, Loss: 0.1038, Train: 0.8372, Val: 0.7961, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.42it/s]
Epoch: 017, Loss: 0.1017, Train: 0.8394, Val: 0.7928, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:46<00:00, 22.34it/s]
Epoch: 018, Loss: 0.1023, Train: 0.8416, Val: 0.8006, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:46<00:00, 22.12it/s]
Epoch: 019, Loss: 0.1010, Train: 0.8369, Val: 0.7859, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.40it/s]
Epoch: 020, Loss: 0.0998, Train: 0.8380, Val: 0.7965, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.42it/s]
Epoch: 021, Loss: 0.1007, Train: 0.8438, Val: 0.7944, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.39it/s]
Epoch: 022, Loss: 0.1000, Train: 0.8412, Val: 0.7971, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.45it/s]
Epoch: 023, Loss: 0.0989, Train: 0.8441, Val: 0.7842, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.49it/s]
Epoch: 024, Loss: 0.0997, Train: 0.8445, Val: 0.7945, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.40it/s]
Epoch: 025, Loss: 0.0989, Train: 0.8432, Val: 0.7913, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:45<00:00, 22.35it/s]
Epoch: 026, Loss: 0.0982, Train: 0.8460, Val: 0.7937, Test: 0.8003
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:46<00:00, 22.27it/s]
Epoch: 027, Loss: 0.0988, Train: 0.8441, Val: 0.8002, Test: 0.8003
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:44<00:00, 23.19it/s]
Epoch: 028, Loss: 0.0985, Train: 0.8442, Val: 0.7880, Test: 0.8003
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:44<00:00, 23.15it/s]
Epoch: 029, Loss: 0.0984, Train: 0.8471, Val: 0.7973, Test: 0.8003
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:44<00:00, 23.23it/s]
Epoch: 030, Loss: 0.0982, Train: 0.8457, Val: 0.7917, Test: 0.8003
