train_loader = DataLoader(train_dataset, 64, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, 256, shuffle=False, num_workers=0)
test_loader = DataLoader(test_dataset, 256, shuffle=False, num_workers=0)

epochs = 30
model = SubFormer(
    hidden_channels=128,
    out_channels=ds.num_tasks,
    num_mp_layers=8,
    num_enc_layers=4,
    mp_dropout=0,
    mp_dropout_edge=0.5,
    enc_dropout=0.2,
    local_mp='agat',
    learn_gating=False,
    activation='relu',
    back_activation='leaky_relu',
    enc_activation='relu',
    aggregation='sum',
    pe_fea=False,
    pe_dim=10,
    n_head=16,
    padding_length=120,
    dim_feedforward=512,
    readout_channels=128,
    concat_pe=False,
    use_deg=True,
    use_lpe=True,
    use_spa=False,
).to(device)
print(model)
model.reset_parameters()
optimizer = Adam(model.parameters(), lr=0.0001,amsgrad=True)

SubFormer(
  (local_mp): LocalMP(
    (atom_encoder): AtomEncoder(
      (embeddings): ModuleList(
        (0-8): 9 x Embedding(100, 128)
      )
    )
    (clique_encoder): Embedding(4, 128)
    (activation): ReLU()
    (back_activation): LeakyReLU(negative_slope=0.01)
    (bond_encoders): ModuleList(
      (0-7): 8 x BondEncoder(
        (embeddings): ModuleList(
          (0-2): 3 x Embedding(6, 128)
        )
      )
    )
    (graph_convs): ModuleList(
      (0-7): 8 x AGATConv(128, phi=GATv2Conv(128, 128, heads=1), num_iters=1, epsilon=0.1, gamma=0.1)
    )
    (graph_norms): ModuleList(
      (0-7): 8 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (sub_norms): ModuleList(
      (0-7): 8 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (atom2clique_lins): ModuleList(
      (0-7): 8 x Linear(in_features=128, out_features=128, bias=True)
    )
    (clique2atom_lins): ModuleList(
      (0-7): 8 x Linear(in_features=128, out_features=128, bias=True)
    )
    (clique): Linear(in_features=128, out_features=128, bias=True)
  )
  (pe): PositionalEncoding(
    (activation): ReLU()
    (deg_emb): Embedding(50, 128)
    (deg_lin): Linear(in_features=128, out_features=128, bias=True)
    (deg_merge): Linear(in_features=128, out_features=128, bias=True)
    (lpe_lin): Linear(in_features=10, out_features=128, bias=True)
    (lpe_merge): Linear(in_features=128, out_features=128, bias=True)
  )
  (encoder): Encoder(
    (activation): ReLU()
    (encoder_layer): TransformerEncoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
      )
      (linear1): Linear(in_features=128, out_features=512, bias=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (linear2): Linear(in_features=512, out_features=128, bias=True)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=512, bias=True)
          (dropout): Dropout(p=0.2, inplace=False)
          (linear2): Linear(in_features=512, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.2, inplace=False)
          (dropout2): Dropout(p=0.2, inplace=False)
        )
      )
    )
    (readout): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=12, bias=True)
    )
  )
)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.81it/s]
/home/zpengmei/mambaforge/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:287: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680572619157/work/aten/src/ATen/NestedTensorImpl.cpp:177.)
  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)
Epoch: 001, Loss: 0.4277, Train: 0.6472, Val: 0.6402, Test: 0.6600
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:03<00:00, 24.55it/s]
Epoch: 002, Loss: 0.2435, Train: 0.7484, Val: 0.7481, Test: 0.7518
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 24.48it/s]
Epoch: 003, Loss: 0.2214, Train: 0.7795, Val: 0.7647, Test: 0.7767
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 24.25it/s]
Epoch: 004, Loss: 0.2125, Train: 0.7962, Val: 0.7739, Test: 0.7940
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 24.01it/s]
Epoch: 005, Loss: 0.2062, Train: 0.8036, Val: 0.7765, Test: 0.7960
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 23.30it/s]
Epoch: 006, Loss: 0.2044, Train: 0.8105, Val: 0.7864, Test: 0.8047
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 23.53it/s]
Epoch: 007, Loss: 0.2007, Train: 0.8170, Val: 0.7844, Test: 0.8047
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 23.28it/s]
Epoch: 008, Loss: 0.1981, Train: 0.8209, Val: 0.7811, Test: 0.8047
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 23.02it/s]
Epoch: 009, Loss: 0.1965, Train: 0.8293, Val: 0.8061, Test: 0.8248
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.78it/s]
Epoch: 010, Loss: 0.1942, Train: 0.8317, Val: 0.7977, Test: 0.8248
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.57it/s]
Epoch: 011, Loss: 0.1904, Train: 0.8441, Val: 0.8121, Test: 0.8334
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.53it/s]
Epoch: 012, Loss: 0.1874, Train: 0.8422, Val: 0.8017, Test: 0.8334
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.54it/s]
Epoch: 013, Loss: 0.1863, Train: 0.8500, Val: 0.8193, Test: 0.8373
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.54it/s]
Epoch: 014, Loss: 0.1843, Train: 0.8554, Val: 0.8186, Test: 0.8373
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.52it/s]
Epoch: 015, Loss: 0.1819, Train: 0.8587, Val: 0.8282, Test: 0.8474
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.50it/s]
Epoch: 016, Loss: 0.1810, Train: 0.8641, Val: 0.8297, Test: 0.8437
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.52it/s]
Epoch: 017, Loss: 0.1784, Train: 0.8693, Val: 0.8296, Test: 0.8437
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.53it/s]
Epoch: 018, Loss: 0.1758, Train: 0.8752, Val: 0.8325, Test: 0.8549
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.50it/s]
Epoch: 019, Loss: 0.1743, Train: 0.8765, Val: 0.8281, Test: 0.8549
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.45it/s]
Epoch: 020, Loss: 0.1720, Train: 0.8781, Val: 0.8292, Test: 0.8549
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.46it/s]
Epoch: 021, Loss: 0.1716, Train: 0.8843, Val: 0.8354, Test: 0.8623
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.46it/s]
Epoch: 022, Loss: 0.1697, Train: 0.8856, Val: 0.8351, Test: 0.8623
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.03it/s]
Epoch: 023, Loss: 0.1692, Train: 0.8860, Val: 0.8407, Test: 0.8647
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.45it/s]
Epoch: 024, Loss: 0.1676, Train: 0.8941, Val: 0.8387, Test: 0.8647
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.46it/s]
Epoch: 025, Loss: 0.1656, Train: 0.8946, Val: 0.8355, Test: 0.8647
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.45it/s]
Epoch: 026, Loss: 0.1635, Train: 0.8987, Val: 0.8339, Test: 0.8647
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.47it/s]
Epoch: 027, Loss: 0.1611, Train: 0.8990, Val: 0.8343, Test: 0.8647
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.45it/s]
Epoch: 028, Loss: 0.1597, Train: 0.9030, Val: 0.8409, Test: 0.8727
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:04<00:00, 22.49it/s]
Epoch: 029, Loss: 0.1611, Train: 0.9051, Val: 0.8346, Test: 0.8727

